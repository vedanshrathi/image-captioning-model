# ğŸ–¼ï¸ Image Caption Generation System (CNN + LSTM + Attention)

This project implements an **Image Caption Generation System** using **Deep Learning**, where a model automatically generates a natural language description for a given image.

It uses:
- **ResNet50 (CNN)** for image feature extraction
- **LSTM** for sequence modeling
- **Attention Mechanism** to focus on relevant image regions
- **Flask + HTML/CSS/JS** for a simple web interface

---

## ğŸ“Œ Features

- Upload an image and generate a caption
- Attention-based image captioning model
- Web-based frontend using Flask
- Trained using real-world datasets (Flickr8k / MS COCO)
- Suitable for **Final Year AI / ML Project**

---

## ğŸ§  Model Architecture

```
Image â†’ ResNet50 â†’ Feature Maps
                     â†“
                Attention Layer
                     â†“
Text Input â†’ Embedding â†’ LSTM â†’ Dense â†’ Caption
```

---

## ğŸ“ Project Structure

```
image_captioning/
â”‚
â”œâ”€â”€ app.py                    # Flask backend
â”œâ”€â”€ inference.py              # Caption generation logic
â”œâ”€â”€ model/
â”‚   â””â”€â”€ train.py              # Model training (with attention)
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ Images/               # Image dataset
â”‚   â””â”€â”€ captions.txt          # Image-caption mapping
â”‚
â”œâ”€â”€ saved_model/
â”‚   â”œâ”€â”€ caption_model.h5      # Trained model (auto-generated)
â”‚   â””â”€â”€ tokenizer.pkl         # Tokenizer (auto-generated)
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Frontend UI
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css             # Styling
â”‚   â””â”€â”€ script.js             # Frontend logic
â”‚
â”œâ”€â”€ venv/                     # Virtual environment
â””â”€â”€ README.md                 # Project documentation
```

---

## ğŸ§ª Dataset Used

Recommended datasets:
- **MS COCO (Best accuracy)**
- Flickr30k
- Flickr8k (for learning/demo)

Each image has multiple captions to improve learning quality.

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install tensorflow flask numpy pillow nltk matplotlib tqdm
```

---

## ğŸ‹ï¸ Train the Model

âš ï¸ Do NOT create model files manually.

```bash
python model/train.py
```

This will automatically generate:
- `saved_model/caption_model.h5`
- `saved_model/tokenizer.pkl`

---

## ğŸš€ Run the Web Application

```bash
python app.py
```

Open browser:
```
http://127.0.0.1:5000
```

Upload an image and click **Generate Caption**.

---

## ğŸ“¸ Sample Output

**Input Image:**  
A person riding a bike on the road

**Generated Caption:**  
> *A man riding a bike on the street*

---

## ğŸ“ Viva Explanation (Short)

> This project uses a CNNâ€“LSTM architecture with an attention mechanism to generate natural language captions for images. The CNN extracts visual features, attention focuses on important regions, and the LSTM generates captions word by word.

---

## ğŸ› ï¸ Technologies Used

- Python
- TensorFlow / Keras
- OpenCV (optional)
- Flask
- HTML, CSS, JavaScript

---

## ğŸ“ˆ Future Enhancements

- Beam Search decoding
- Attention heatmap visualization
- Voice-based caption output
- VQA (Visual Question Answering)

---

## ğŸ‘¨â€ğŸ“ Author

Final Year AI / ML Project  
Developed for academic and learning purposes.

---

â­ *If you like this project, feel free to extend or improve it!* â­
